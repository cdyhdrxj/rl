{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d05ac21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install numpy\n",
    "# ! pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d482b31e",
   "metadata": {},
   "source": [
    "## Q-Learning и SARSA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01714a02",
   "metadata": {},
   "source": [
    "### Описание МППР + модель среды\n",
    "\n",
    "Будем случайно моделировать среду\n",
    "\n",
    "Необходимо моделировать\n",
    "- препятствия\n",
    "- труднопроходимую поверхность (болото)\n",
    "\n",
    "Цель - добраться из точки A в точку B\n",
    "\n",
    "Считаем, что среда - GridWorld - ограниченный прямоугольник, разбитый на клетки  \n",
    "Пусть в каждой клетке сетки находится целое число $x$\n",
    "\n",
    "Каждая клетка может быть:\n",
    "- пустой: $x = 0$\n",
    "- содержать препятствие: $x = 10$\n",
    "- быть болотом с некоторым коэффициентом проходимости: $1 \\le x <= 5$\n",
    "\n",
    "Смысл значения $x$ (**динамика среды**): при попытке перехода агента в клетку со значением $x$\n",
    "- с вероятностью $\\frac{x}{10}$ агент остаётся в своей текущей клетке\n",
    "- с вероятностью $1 - \\frac{x}{10}$ агент выполняет переход\n",
    "\n",
    "**Состояние** - $(\\Delta i, \\Delta j, x_{cur}, x_{left}, x_{right}, x_{up}, x_{down})$\n",
    "\n",
    "- $\\Delta i, \\Delta j$ - разность координат до цели - мб отрицальные - чтобы понять где агент относительно цели\n",
    "- $x$ - значения проходимости в текущей клетке и по соседним - т.е. агент видит, что происходит в текущей клетке и в соседних\n",
    "\n",
    "*если соседная клетка - граница прямоугольника - она считается препятствием ($x = 10$)*\n",
    "\n",
    "**Действия**:\n",
    "- шаг вверх\n",
    "- шаг вниз\n",
    "- шаг вправо\n",
    "- шаг влево"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "603ccbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from random import randint\n",
    "from numpy.random import choice\n",
    "from collections import deque\n",
    "from math import sqrt\n",
    "\n",
    "OBSTACLE = 10\n",
    "MAX_SWAMP = 5\n",
    "STEPS = [(-1, 0), (1, 0), (0, -1), (0, 1)]\n",
    "\n",
    "def generate_environment(n, m, p_walk, p_obstacle, number_mud):\n",
    "    # Находится ли точка внутри сетки\n",
    "    def in_grid(i, j):\n",
    "        return 0 <= i < n and 0 <= j < m\n",
    "\n",
    "    # Возвращает манхеттенское расстояние между (i1, j1) и (i2, j2)\n",
    "    def dist(i1, j1, i2, j2):\n",
    "        return abs(i1 - i2) + abs(j1 - j2)\n",
    "\n",
    "    def random_point():\n",
    "        return (randint(0, n-1), randint(0, m-1))\n",
    "\n",
    "    grid = [[-1] * m for _ in range(n)]\n",
    "    start = random_point()\n",
    "    finish = random_point() # а что если совпадут?\n",
    "\n",
    "    # --- Генерация случайного пути между стартом и финишем ---\n",
    "\n",
    "    i, j = start\n",
    "    fi, fj = finish\n",
    "\n",
    "    while (i, j) != (fi, fj):\n",
    "        grid[i][j] = 0\n",
    "        # С вероятностью p_walk делаем шаг в случайную сторону (равновероятно)\n",
    "        if choice([0, 1], p=[1 - p_walk, p_walk]):\n",
    "            di, dj = random.choice(STEPS)\n",
    "            ni, nj = i + di, j + dj\n",
    "            if in_grid(ni, nj):\n",
    "                i, j = ni, nj\n",
    "        # С вероятностью 1 - p_walk - шаг в направлении финиша\n",
    "        else:\n",
    "            options = []\n",
    "            for di, dj in STEPS:\n",
    "                ni, nj = i + di, j + dj\n",
    "                if in_grid(ni, nj) and dist(ni, nj, fi, fj) < dist(i, j, fi, fj):\n",
    "                    options.append((ni, nj))\n",
    "\n",
    "            i, j = random.choice(options)\n",
    "\n",
    "    grid[fi][fj] = 0\n",
    "\n",
    "    # --- Генерация препятствий ---\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            # Нельзя поставить препятствие на пути из старта в финиш\n",
    "            # В остальных клетках - с вероятностью p_obstacle\n",
    "            if grid[i][j] == -1 and choice([0, 1], p=[1 - p_obstacle, p_obstacle]):\n",
    "                grid[i][j] = OBSTACLE\n",
    "\n",
    "    # --- Генерация труднопроходимых поверхностей ---\n",
    "\n",
    "    for _ in range(number_mud):\n",
    "        ci, cj = random_point()\n",
    "        strength = randint(1, MAX_SWAMP)\n",
    "        queue = deque()\n",
    "        queue.append((ci, cj, strength))\n",
    "\n",
    "        while queue:\n",
    "            i, j, s = queue.popleft()\n",
    "\n",
    "            for di, dj in STEPS:\n",
    "                ni, nj = i + di, j + dj\n",
    "                p_mud = sqrt(s / 10)\n",
    "                if in_grid(ni, nj) and grid[ni][nj] < 1 and choice([0, 1], p=[1 - p_mud, p_mud]):\n",
    "                    ns = grid[ni][nj] = randint(max(1, s-1), s)\n",
    "                    queue.append((ni, nj, ns))\n",
    "\n",
    "    # --- В остальных точках - проходимая поверхность ---\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            if grid[i][j] == -1:\n",
    "                grid[i][j] = 0\n",
    "\n",
    "    return grid, start, finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "70f5e3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Возвращает случайно сгенерированный эпизод\n",
    "# Содержит:\n",
    "# - сетку размером n x m\n",
    "# - начальную и конечную точки\n",
    "# - функцию вознаграждения\n",
    "\n",
    "# Функция вознаграждения:\n",
    "# -1 за один шаг (не важно, случился переход или нет)\n",
    "# +1000 за финиш\n",
    "\n",
    "# x: целое число от 0 (нет препятствия) до 10 (препятствие - туда перейти нельзя)\n",
    "# p (вероятность перехода в клетку с x) = 1 - (x / 10)\n",
    "# иначе чел остается в клетке\n",
    "class Environment:\n",
    "    # Случайно сгенерированная среда\n",
    "    def __init__(self, n, m, p_walk, p_obstacle, number_mud):\n",
    "        self.n = n\n",
    "        self.m = m\n",
    "        self.grid, self.start, self.finish = generate_environment(n, m, p_walk, p_obstacle, number_mud)\n",
    "        self.agent_position = self.start\n",
    "\n",
    "    # Является ли состояние терминальным\n",
    "    @staticmethod\n",
    "    def is_terminal(state):\n",
    "        di, dj, _, _, _, _, _ = state\n",
    "        return di == 0 and dj == 0\n",
    "\n",
    "    # Возвращает состояние по клетке, в которой находится агент\n",
    "    def get_state(self):\n",
    "        i, j = self.agent_position\n",
    "        fi, fj = self.finish\n",
    "\n",
    "        def cell(x, y):\n",
    "            if 0 <= x < self.n and 0 <= y < self.m:\n",
    "                return self.grid[x][y]\n",
    "            return 10\n",
    "\n",
    "        return (\n",
    "            i - fi,\n",
    "            j - fj,\n",
    "            cell(i, j),\n",
    "            cell(i-1, j),\n",
    "            cell(i+1, j),\n",
    "            cell(i, j-1),\n",
    "            cell(i, j+1)\n",
    "        )\n",
    "\n",
    "    # Шаг агента - возвращает следующее состояние, вознаграждение\n",
    "    def step(self, move):\n",
    "        i, j = self.agent_position\n",
    "\n",
    "        di, dj = {\n",
    "            0: (-1, 0),  # наверх\n",
    "            1: (1, 0),   # вниз\n",
    "            2: (0, -1),  # влево\n",
    "            3: (0, 1)    # вправо\n",
    "        }[move]\n",
    "\n",
    "        ni, nj = i + di, j + dj\n",
    "\n",
    "        # Ушли за границы, не двигаемся с места\n",
    "        if not (0 <= ni < self.n and 0 <= nj < self.m):\n",
    "            reward = -1\n",
    "            return self.get_state(), reward\n",
    "\n",
    "        # Новое состояние\n",
    "        p_move = 1 - self.grid[ni][nj] / 10\n",
    "        moved = np.random.choice([0, 1], p=[1-p_move, p_move])\n",
    "        self.agent_position = (ni, nj) if moved else (i, j)\n",
    "\n",
    "        reward = -1\n",
    "\n",
    "        if self.agent_position == self.finish:\n",
    "            reward = 1000\n",
    "\n",
    "        return self.get_state(), reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0bc7fe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# это нагенерено чатгпт\n",
    "#\n",
    "# Визуализирует среду сеткой цветных клеточек:\n",
    "# - красная клетка - точка старта или финиша\n",
    "# - зеленая клетка - препятствие\n",
    "# - серая клетка - труднопроходимая поверхность (чем темнее - тем сложнее выйти)\n",
    "def visualize_array(arr, special_points):\n",
    "    \"\"\"\n",
    "    arr: 2D массив целых чисел от 0 до 10\n",
    "    special_points: список кортежей (i,j) для красных точек\n",
    "    \"\"\"\n",
    "    if not np.issubdtype(arr.dtype, np.integer):\n",
    "        raise ValueError(\"Массив должен содержать только целые числа\")\n",
    "    if arr.min() < 0 or arr.max() > 10:\n",
    "        raise ValueError(\"Значения массива должны быть от 0 до 10\")\n",
    "\n",
    "    # Создаем RGB картинку\n",
    "    rgb_array = np.zeros((arr.shape[0], arr.shape[1], 3))\n",
    "\n",
    "    # Основная градация серого (0 - белый, 1..9 - оттенки серого)\n",
    "    for i in range(arr.shape[0]):\n",
    "        for j in range(arr.shape[1]):\n",
    "            val = arr[i,j]\n",
    "            if val == 10:\n",
    "                rgb_array[i,j] = [0, 0.5, 0]  # темно-зеленый\n",
    "            else:\n",
    "                shade = 1 - val/10  # 0 - белый, 9 - темно-серый\n",
    "                rgb_array[i,j] = [shade, shade, shade]\n",
    "\n",
    "    # Красим специальные точки в красный\n",
    "    for (i,j) in special_points:\n",
    "        rgb_array[i,j] = [1, 0, 0]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(rgb_array)\n",
    "\n",
    "    # убираем деления и подписи\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    # включаем рамку\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_linewidth(1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9b54c0d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Пример генерации среды\n",
    "grid, start, finish = generate_environment(\n",
    "    n=40,\n",
    "    m=40,\n",
    "    p_walk=0.6,\n",
    "    p_obstacle=0.2,\n",
    "    number_mud=30, # должно быть пропорционально размерам сетки\n",
    ")\n",
    "\n",
    "# Визуализация среды\n",
    "visualize_array(np.array(grid), [start, finish])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bd0b2b",
   "metadata": {},
   "source": [
    "### Реализация Q-learning\n",
    "\n",
    "<img src=\"img/q-learning.png\" alt=\"Q-learning\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166a940c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearning:\n",
    "    def __init__(self, alpha, epsilon, gamma):\n",
    "        self.alpha = alpha\n",
    "        self.epsilon = epsilon\n",
    "        self.gamma = gamma\n",
    "        # Параметр Q-функции: (state, action)\n",
    "        self.Q = dict()\n",
    "\n",
    "    # Возвращает текущее значение Q-функции для состояния state и действия action\n",
    "    # Для терминального состояния - 0\n",
    "    # Для неинициализированного состояния - 0\n",
    "    def _get_q_value(self, state, action):\n",
    "        if Environment.is_terminal(state):\n",
    "            return 0\n",
    "        return self.Q.get((state, action), 0)\n",
    "\n",
    "    # Возвращает максимум Q-функции по всем действиям из состояния state\n",
    "    def _best_action_value(self, state):\n",
    "        if Environment.is_terminal(state):\n",
    "            return 0\n",
    "        return max(self._get_q_value(state, a) for a in range(4))\n",
    "\n",
    "    # Выбор действия в состоянии state\n",
    "    def _choose_action(self, state):\n",
    "        # С вероятностью epsilon - равновероятно случайное действие\n",
    "        if random.random() < self.epsilon:\n",
    "            return randint(0, 3)\n",
    "        # Иначе - аргмаксимум Q-функции по всем действиям из состояния state\n",
    "        qs = [self._get_q_value(state, a) for a in range(4)]\n",
    "        return int(np.argmax(qs))\n",
    "\n",
    "    def learn(self, max_episodes, max_steps):\n",
    "        for _ in range(max_episodes):\n",
    "            n, m = randint(10, 20), randint(10, 20)\n",
    "            env = Environment(\n",
    "                    n=n,\n",
    "                    m=m,\n",
    "                    p_walk=0.5,\n",
    "                    p_obstacle=random.uniform(0.1, 0.2),\n",
    "                    number_mud=random.randint(int(5 * (n*m)/(20*20)), int(8 * (n*m)/(20*20))),\n",
    "                )\n",
    "            state = env.get_state()\n",
    "\n",
    "            self.epsilon = max(0.01, self.epsilon * 0.995)\n",
    "\n",
    "            for _ in range(max_steps):\n",
    "                if env.is_terminal(state):\n",
    "                    break\n",
    "\n",
    "                action = self._choose_action(state)\n",
    "                next_state, reward = env.step(action)\n",
    "\n",
    "                old_q = self._get_q_value(state, action)\n",
    "                target = reward + self.gamma * self._best_action_value(next_state)\n",
    "\n",
    "                self.Q[(state, action)] = old_q + self.alpha * (target - old_q)\n",
    "                state = next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b39ea52",
   "metadata": {},
   "source": [
    "#### Пример обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "59e94af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = QLearning(alpha=0.1, epsilon=0.3, gamma=1)\n",
    "q.learn(max_episodes=20000, max_steps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "56b9a641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "MAX_STEPS = 10**5\n",
    "\n",
    "def try_model():\n",
    "    n, m = 10, 10\n",
    "    env = Environment(\n",
    "        n=n,\n",
    "        m=m,\n",
    "        p_walk=0.5,\n",
    "        p_obstacle=random.uniform(0.1, 0.2),\n",
    "        number_mud=random.randint(int(5 * (n*m)/(20*20)), int(8 * (n*m)/(20*20)))\n",
    "    )\n",
    "\n",
    "    state = env.get_state()\n",
    "    path = [env.agent_position]\n",
    "\n",
    "    def get_optimal_action(state):\n",
    "        qs = [q._get_q_value(state, a) for a in range(4)]\n",
    "        return int(np.argmax(qs))\n",
    "\n",
    "    for _ in range(MAX_STEPS):\n",
    "        if env.is_terminal(state):\n",
    "            break\n",
    "        action = get_optimal_action(state)\n",
    "        state, _ = env.step(action)\n",
    "        path.append(env.agent_position)\n",
    "\n",
    "    return len(path)\n",
    "\n",
    "# --- Визуализация ---\n",
    "# grid = np.array(env.grid)\n",
    "# img = np.zeros((n, m, 3), dtype=float)\n",
    "\n",
    "# for i in range(n):\n",
    "#     for j in range(m):\n",
    "#         if grid[i,j] == 10:\n",
    "#             img[i,j] = [0,0,0]           # препятствие — чёрное\n",
    "#         elif grid[i,j] == 0:\n",
    "#             img[i,j] = [1,1,1]           # пустое — белое\n",
    "#         else:\n",
    "#             shade = 0.3 + 0.7*(grid[i,j]/10)  # болотный градиент\n",
    "#             img[i,j] = [0, shade, shade]\n",
    "\n",
    "# plt.imshow(img, origin='upper')\n",
    "# plt.scatter(env.start[1], env.start[0], c='green', marker='o', s=80, label='Start')\n",
    "# plt.scatter(env.finish[1], env.finish[0], c='red', marker='x', s=80, label='Finish')\n",
    "\n",
    "# # Рисуем путь агента\n",
    "# path_i, path_j = zip(*path)\n",
    "# plt.plot(path_j, path_i, color='blue', linewidth=2, label='Agent path')\n",
    "\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "230d7a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 32.,  35., 125.,  58.,  82.,  35.,  52.,  16.,  13.,   4.]),\n",
       " array([ 1. ,  2.5,  4. ,  5.5,  7. ,  8.5, 10. , 11.5, 13. , 14.5, 16. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 1000\n",
    "path_lens = []\n",
    "cnt = 0\n",
    "for _ in range(N):\n",
    "    l = try_model()\n",
    "    if l < MAX_STEPS:\n",
    "        path_lens.append(l)\n",
    "    else:\n",
    "        cnt += 1\n",
    "    if _ % 100 == 0:\n",
    "        print(_)\n",
    "path_lens = sorted(path_lens)\n",
    "\n",
    "plt.hist(path_lens, bins=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60bfb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "520\n"
     ]
    }
   ],
   "source": [
    "# Количество эпизодов, для которых не нашёлся путь за MAX_STEPS шагов\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd01e76",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64035e89",
   "metadata": {},
   "source": [
    "## SARSA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1108f64",
   "metadata": {},
   "source": [
    "### Реализация SARSA\n",
    "\n",
    "<img src=\"img/sarsa.png\" alt=\"SARSA\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "beb83ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sarsa:\n",
    "    def __init__(self, alpha, epsilon, gamma):\n",
    "        self.alpha = alpha\n",
    "        self.epsilon = epsilon\n",
    "        self.gamma = gamma\n",
    "        self.Q = dict()\n",
    "\n",
    "    # Возвращает текущее значение Q-функции для состояния state и действия action\n",
    "    # Для терминального состояния - 0\n",
    "    # Для неинициализированного состояния - 0\n",
    "    def _get_q_value(self, state, action):\n",
    "        if Environment.is_terminal(state):\n",
    "            return 0\n",
    "        return self.Q.get((state, action), 0)\n",
    "\n",
    "    # Возвращает максимум Q-функции по всем действиям из состояния state\n",
    "    def _best_action_value(self, state):\n",
    "        if Environment.is_terminal(state):\n",
    "            return 0\n",
    "        return max(self._get_q_value(state, a) for a in range(4))\n",
    "\n",
    "    # Выбор действия в состоянии state\n",
    "    def _choose_action(self, state):\n",
    "        # С вероятностью epsilon - равновероятно случайное действие\n",
    "        if random.random() < self.epsilon:\n",
    "            return randint(0, 3)\n",
    "        # Иначе - аргмаксимум Q-функции по всем действиям из состояния state\n",
    "        qs = [self._get_q_value(state, a) for a in range(4)]\n",
    "        return int(np.argmax(qs))\n",
    "\n",
    "    def learn(self, max_episodes, max_steps):\n",
    "        for _ in range(max_episodes):\n",
    "            n, m = randint(10, 20), randint(10, 20)\n",
    "            env = Environment(\n",
    "                    n=n,\n",
    "                    m=m,\n",
    "                    p_walk=0.5,\n",
    "                    p_obstacle=random.uniform(0.1, 0.2),\n",
    "                    number_mud=random.randint(int(5 * (n*m)/(20*20)), int(8 * (n*m)/(20*20))),\n",
    "                )\n",
    "            state = env.get_state()\n",
    "            action = self._choose_action(state)   # !!!\n",
    "\n",
    "            for _ in range(max_steps):\n",
    "                if env.is_terminal(state):\n",
    "                    break\n",
    "\n",
    "                next_state, reward = env.step(action)\n",
    "                next_action = self._choose_action(next_state)  # !!!\n",
    "\n",
    "                old_q = self._get_q_value(state, action)\n",
    "                target = reward + self.gamma *  self._get_q_value(next_state, next_action) # !!!\n",
    "\n",
    "                self.Q[(state, action)] = old_q + self.alpha * (target - old_q)\n",
    "                state = next_state\n",
    "                action = next_action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f265e519",
   "metadata": {},
   "source": [
    "#### Пример обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c82a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Sarsa(alpha=0.1, epsilon=0.3, gamma=1)\n",
    "s.learn(max_episodes=20000, max_steps=10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
