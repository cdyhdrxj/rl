{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d05ac21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install numpy\n",
    "# ! pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d482b31e",
   "metadata": {},
   "source": [
    "## Q-Learning и SARSA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01714a02",
   "metadata": {},
   "source": [
    "### Описание МППР + модель среды\n",
    "\n",
    "Будем случайно моделировать среду\n",
    "\n",
    "Необходимо моделировать\n",
    "- препятствия\n",
    "- труднопроходимую поверхность (болото)\n",
    "\n",
    "Цель - добраться из точки A в точку B\n",
    "\n",
    "Считаем, что среда - GridWorld - ограниченный прямоугольник, разбитый на клетки  \n",
    "Пусть в каждой клетке сетки находится целое число $x$\n",
    "\n",
    "Каждая клетка может быть:\n",
    "- пустой: $x = 0$\n",
    "- содержать препятствие: $x = 10$\n",
    "- быть болотом с некоторым коэффициентом проходимости: $1 \\le x \\le 5$\n",
    "\n",
    "Смысл значения $x$ (**динамика среды**): при попытке перехода агента из текущей клетки со значением $x$\n",
    "- с вероятностью $\\frac{x}{10}$ агент остаётся в своей текущей клетке\n",
    "- с вероятностью $1 - \\frac{x}{10}$ агент выполняет переход\n",
    "\n",
    "НО: если агент пытается перейти в клетку с препятствием $x = 10$ или за границы сетки, переход не выполняется никогда\n",
    "\n",
    "**Состояние** - $(\\Delta i, \\Delta j, x_{cur}, x_{up}, x_{down}, x_{left}, x_{right})$\n",
    "\n",
    "- $\\Delta i, \\Delta j$ - разность координат до цели - могут быть отрицательные - чтобы понять, где агент относительно цели\n",
    "- $x$ - значения проходимости в текущей клетке и по соседним - т.е. агент видит, что происходит в текущей клетке и в соседних\n",
    "\n",
    "*если соседняя клетка - граница прямоугольника - она считается препятствием ($x = 10$)*\n",
    "\n",
    "**Действия**:\n",
    "- шаг вверх\n",
    "- шаг вниз\n",
    "- шаг вправо\n",
    "- шаг влево\n",
    "\n",
    "**Вознаграждения:**\n",
    "- -1 за один шаг (не важно, случился переход или нет)\n",
    "- +1000 за финиш"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603ccbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from random import randint\n",
    "from numpy.random import choice\n",
    "from collections import deque\n",
    "from math import sqrt\n",
    "\n",
    "OBSTACLE = 10\n",
    "MAX_SWAMP = 5\n",
    "STEPS = [(-1, 0), (1, 0), (0, -1), (0, 1)]\n",
    "\n",
    "def generate_environment(n, m, p_walk, p_obstacle, number_mud):\n",
    "    # Находится ли точка внутри сетки\n",
    "    def in_grid(i, j):\n",
    "        return 0 <= i < n and 0 <= j < m\n",
    "\n",
    "    # Возвращает манхеттенское расстояние между (i1, j1) и (i2, j2)\n",
    "    def dist(i1, j1, i2, j2):\n",
    "        return abs(i1 - i2) + abs(j1 - j2)\n",
    "\n",
    "    def random_point():\n",
    "        return (randint(0, n-1), randint(0, m-1))\n",
    "\n",
    "    grid = [[-1] * m for _ in range(n)]\n",
    "    start = random_point()\n",
    "    finish = random_point()\n",
    "\n",
    "    # --- Генерация случайного пути между стартом и финишем ---\n",
    "\n",
    "    i, j = start\n",
    "    fi, fj = finish\n",
    "\n",
    "    while (i, j) != (fi, fj):\n",
    "        grid[i][j] = 0\n",
    "        # С вероятностью p_walk делаем шаг в случайную сторону (равновероятно)\n",
    "        if choice([0, 1], p=[1 - p_walk, p_walk]):\n",
    "            di, dj = random.choice(STEPS)\n",
    "            ni, nj = i + di, j + dj\n",
    "            if in_grid(ni, nj):\n",
    "                i, j = ni, nj\n",
    "        # С вероятностью 1 - p_walk - шаг в направлении финиша\n",
    "        else:\n",
    "            options = []\n",
    "            for di, dj in STEPS:\n",
    "                ni, nj = i + di, j + dj\n",
    "                if in_grid(ni, nj) and dist(ni, nj, fi, fj) < dist(i, j, fi, fj):\n",
    "                    options.append((ni, nj))\n",
    "\n",
    "            i, j = random.choice(options)\n",
    "\n",
    "    grid[fi][fj] = 0\n",
    "\n",
    "    # --- Генерация препятствий ---\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            # Нельзя поставить препятствие на пути из старта в финиш\n",
    "            # В остальных клетках - с вероятностью p_obstacle\n",
    "            if grid[i][j] == -1 and choice([0, 1], p=[1 - p_obstacle, p_obstacle]):\n",
    "                grid[i][j] = OBSTACLE\n",
    "\n",
    "    # --- Генерация труднопроходимых поверхностей ---\n",
    "\n",
    "    for _ in range(number_mud):\n",
    "        # Случайная точка - центр \"болота\"\n",
    "        ci, cj = random_point()\n",
    "\n",
    "        strength = randint(1, MAX_SWAMP)\n",
    "        if grid[ci][cj] != OBSTACLE:\n",
    "            grid[ci][cj] = strength\n",
    "\n",
    "        queue = deque()\n",
    "        queue.append((ci, cj, strength))\n",
    "\n",
    "        # Будем распространять болото в ширину наподобие BFS\n",
    "        while queue:\n",
    "            i, j, s = queue.popleft()\n",
    "\n",
    "            for di, dj in STEPS:\n",
    "                ni, nj = i + di, j + dj\n",
    "                # Вероятность распространения болота в соседную клетку\n",
    "                p_mud = sqrt(s / 10)\n",
    "                if in_grid(ni, nj) and grid[ni][nj] < 1 and choice([0, 1], p=[1 - p_mud, p_mud]):\n",
    "                    # Проходимость соседней точки либо такая же, либо на 1 меньше\n",
    "                    ns = grid[ni][nj] = randint(max(1, s-1), s)\n",
    "                    queue.append((ni, nj, ns))\n",
    "\n",
    "    # --- В остальных точках - проходимая поверхность ---\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            if grid[i][j] == -1:\n",
    "                grid[i][j] = 0\n",
    "\n",
    "    return grid, start, finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70f5e3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Возвращает случайно сгенерированную среду\n",
    "# Содержит:\n",
    "# - сетку размером n x m\n",
    "# - начальную и конечную точки\n",
    "# - функцию вознаграждения\n",
    "class Environment:\n",
    "    # Случайно сгенерированная среда\n",
    "    def __init__(self, n, m, p_walk, p_obstacle, number_mud):\n",
    "        self.n = n\n",
    "        self.m = m\n",
    "        self.grid, self.start, self.finish = generate_environment(n, m, p_walk, p_obstacle, number_mud)\n",
    "        self.agent_position = self.start\n",
    "\n",
    "    # Является ли состояние терминальным\n",
    "    @staticmethod\n",
    "    def is_terminal(state):\n",
    "        di, dj, _, _, _, _, _ = state\n",
    "        return di == 0 and dj == 0\n",
    "\n",
    "    # Возвращает состояние по клетке, в которой находится агент\n",
    "    def get_state(self):\n",
    "        i, j = self.agent_position\n",
    "        fi, fj = self.finish\n",
    "\n",
    "        def cell(x, y):\n",
    "            if 0 <= x < self.n and 0 <= y < self.m:\n",
    "                return self.grid[x][y]\n",
    "            return 10\n",
    "\n",
    "        return (\n",
    "            i - fi,\n",
    "            j - fj,\n",
    "            cell(i, j),\n",
    "            cell(i-1, j),\n",
    "            cell(i+1, j),\n",
    "            cell(i, j-1),\n",
    "            cell(i, j+1)\n",
    "        )\n",
    "\n",
    "    # Шаг агента - возвращает следующее состояние, вознаграждение\n",
    "    def step(self, move):\n",
    "        i, j = self.agent_position\n",
    "\n",
    "        di, dj = {\n",
    "            0: (-1, 0),  # наверх\n",
    "            1: (1, 0),   # вниз\n",
    "            2: (0, -1),  # влево\n",
    "            3: (0, 1)    # вправо\n",
    "        }[move]\n",
    "\n",
    "        ni, nj = i + di, j + dj\n",
    "\n",
    "        # Ушли за границы, не двигаемся с места\n",
    "        if not (0 <= ni < self.n and 0 <= nj < self.m):\n",
    "            reward = -1\n",
    "            return self.get_state(), reward\n",
    "\n",
    "        # Новое состояние\n",
    "        if self.grid[ni][nj] != OBSTACLE:\n",
    "            p_move = 1 - self.grid[i][j] / 10\n",
    "            moved = np.random.choice([0, 1], p=[1-p_move, p_move])\n",
    "\n",
    "            self.agent_position = (ni, nj) if moved else (i, j)\n",
    "\n",
    "        reward = -1\n",
    "\n",
    "        if self.agent_position == self.finish:\n",
    "            reward = 1000\n",
    "\n",
    "        return self.get_state(), reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bc7fe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# это нагенерено чатгпт\n",
    "#\n",
    "# Визуализирует среду сеткой цветных клеточек:\n",
    "# - красная клетка - точка старта или финиша\n",
    "# - зеленая клетка - препятствие\n",
    "# - серая клетка - труднопроходимая поверхность (чем темнее - тем сложнее выйти)\n",
    "def visualize_array(arr, special_points):\n",
    "    \"\"\"\n",
    "    arr: 2D массив целых чисел от 0 до 10\n",
    "    special_points: список кортежей (i,j) для красных точек\n",
    "    \"\"\"\n",
    "    if not np.issubdtype(arr.dtype, np.integer):\n",
    "        raise ValueError(\"Массив должен содержать только целые числа\")\n",
    "    if arr.min() < 0 or arr.max() > 10:\n",
    "        raise ValueError(\"Значения массива должны быть от 0 до 10\")\n",
    "\n",
    "    # Создаем RGB картинку\n",
    "    rgb_array = np.zeros((arr.shape[0], arr.shape[1], 3))\n",
    "\n",
    "    # Основная градация серого (0 - белый, 1..9 - оттенки серого)\n",
    "    for i in range(arr.shape[0]):\n",
    "        for j in range(arr.shape[1]):\n",
    "            val = arr[i,j]\n",
    "            if val == 10:\n",
    "                rgb_array[i,j] = [0, 0.5, 0]  # темно-зеленый\n",
    "            else:\n",
    "                shade = 1 - val/10  # 0 - белый, 9 - темно-серый\n",
    "                rgb_array[i,j] = [shade, shade, shade]\n",
    "\n",
    "    # Красим специальные точки в красный\n",
    "    for (i,j) in special_points:\n",
    "        rgb_array[i,j] = [1, 0, 0]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(rgb_array)\n",
    "\n",
    "    # убираем деления и подписи\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    # включаем рамку\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_linewidth(1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9b54c0d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAD0tJREFUeJzt3TFu3ObWBuBPRuDAmikNG5ZWEYza7CDyIlLI3e2NFHFjpL9dtAxNlqFBFpBaUhy41NiJC88tjHuuf+CXeEY6/kxKz1M50BeSQ3L4gkpen53NZrNpANBae/C1DwCA8RAKAAShAEAQCgAEoQBAEAoAhG+GFnz8+LG9ffu2tdba7u5u29nZ+eIHBUCdzWbT3r1711pr7fHjx+3Bg6vfBwZD4e3bt+3p06d1RwfAV/PmzZv25MmTK3/u10cAhME3hd3d3fjzmzdv2mw2u9UO56/nqXWXP13eaj9Td3FxkVr3559/luzvu+++K9lOa7lr/O9n/y7Z148//phalzmml+3l4Jpnz54NrvnXxb9Sx9TzHq/83mXvzSGZc5ndX2ZbmXMwxudOxbVbr9fxG5/Pn+n/n8FQ+Py/Icxms1uHQnuYW3br/Uzc0IX7r0ePHpXsr/R8J67xt99+W7Kr9HEnjulhYlHquMd4jxceU/berNhXdn+pbSXOwSifO8X309B/F/brIwCCUAAgCAUAglAAIAgFAIJQACAM/i+p1TavxjfobedV3V/dUfX59o/3y/a3XC4H16xWq9T+Mn7d+7VkOy/OXwyuOX91ntrWz+3n2x5Oa621o6Oj4TVteE1vld+7qt5A5f729vYG15wsTioOp7WWe2aM8VmX4U0BgCAUAAhCAYAgFAAIQgGAIBQACEIBgCAUAAhbldfmr+fX/t3elWWNTDnk7OhscE22BJYx1TLK89XzwTWZYk/VcJWsqsJZb2MsQ2YKjL1lCmettXawPBhcs1n0/W5mrktVwS17D1y7vw+pTbTWvCkA8BmhAEAQCgAEoQBAEAoABKEAQBAKAAShAEAQCgCErRrNlz9dttlsdqsdnp/nxidWqWoe9lbSYtxyW8M7y52n5UnN2MPeIx2rnB6eptZlmroZx8fHJdvJyoxJPd0bPgfZZ0HX73ByKm1lE7nKdftbr9dt/ss8tR1vCgAEoQBAEAoABKEAQBAKAAShAEAQCgAEoQBA2NlsNtc2LNbrdZvPP5UeLi/7ldcyo/qqinDZsYD33WqVa/ZkrkvV9c2MGm2trkiUKUlly2tV92/vMalHR0eDa6ZcCK1SdQ4qjnub57g3BQCCUAAgCAUAglAAIAgFAIJQACAIBQCCUAAgbDV5bf563trD2+2wd4HkrquavJYpplVOzctMHTtZDE9wyxbFqpwdnQ2uyZYhM+dgjNcuY6pFsUpTnfroTQGAIBQACEIBgCAUAAhCAYAgFAAIQgGAIBQACN0nr2XLGpnih8lrdZbLZdm2Dg8Py7Y1ZIz3U6X94/3BNZUFvqpzkJ2Il9Fzal5l6a5qfxX3uMlrANyIUAAgCAUAglAAIAgFAIJQACAIBQCCUAAgCAUAwlbjOCv0HtN3cXExuCbTGm1tnKNEq1qTY2x1VzZQ73L7fbFYDK7JjOxsLddEzoxJzazp2XxvbZxt5Yzezx1vCgAEoQBAEAoABKEAQBAKAAShAEAQCgAEoQBA6D6Os7dMaedgeZDa1hjLaxmZos3Z0VmHI/mfbGFwyFSvSaXKMaKZsmdG9juV4RrfnnGcANyIUAAgCAUAglAAIAgFAIJQACAIBQCCUAAgdJ+8llU12aiy2DNVVeWfynOpkJS7xzMqz2VVee308HRwTWZiXGt9p5xVmupxe1MAIAgFAIJQACAIBQCCUAAgCAUAglAAIAgFAMJoy2s9Sx0ni5Nu+xqrqiJVa+Ms5IxR1XmqLEllJqZlpvRlJuttFrljGuN5ypjq98CbAgBBKAAQhAIAQSgAEIQCAEEoABCEAgBBKAAQhAIAoXujOduczbQBV6vVbQ9ntLLnKTP2sGo7vUebTnWcYW+9z0GqrVx4TFX3QWZN5fNpqrwpABCEAgBBKAAQhAIAQSgAEIQCAEEoABCEAgBhZ7PZXNvCWK/XbT6ft9Zau7y8bLPZrM+BFY6HHDLlIkqmwLdYLAbXZM53dmzp4eFhat0U9S7U3eUCX++iWM9nSlava7fNc9ybAgBBKAAQhAIAQSgAEIQCAEEoABCEAgBBKAAQRlteY3yWy2VqXVV5rbK4dd9LYAp195vyGgA3IhQACEIBgCAUAAhCAYAgFAAIQgGAIBQACN987QO4j6ZaNqqcqDbVAtQYC3VjvFfGeH3HeO0qp8FVnU9vCgAEoQBAEAoABKEAQBAKAAShAEAQCgAEoQBAEAoAhK3GcbaXrbWHV68dYwM1I9sqnOrnyxhjs7JSz4btlO+nzLGfLE5K9vV89Ty1boznKaPqO1XSsv7QWvvl0x+N4wQgTSgAEIQCAEEoABCEAgBBKAAQhAIAQSgAELYqrw2VHiBrqiNJe+tdgMo4Pj4u2c6L8xcl22ltuiNCe9nmOe5NAYAgFAAIQgGAIBQACEIBgCAUAAhCAYAgFAAIpeW18/PzwR3u7e1teYiMxZQnimXc53LTNpbL5eCai4uLDkfyP0dHR133lzGm+0l5DYAbEQoABKEAQBAKAAShAEAQCgAEoQBAEAoAhG8qN5YprOwf76e2VVXqGFOBZOp6n6fe126q07t6H9Pz1fPBNaeHp4NrMmXX1voX4e47bwoABKEAQBAKAAShAEAQCgAEoQBAEAoABKEAQBAKAIStGs2///57e/To0ZU/zzQUz47OUvsaY3O0p96jL3uf76leX8eUs1gsSta0lhv/2Vv2+1mxnd7X15sCAEEoABCEAgBBKAAQhAIAQSgAEIQCAEEoABB2NpvNtc2I9Xrd5vP5p3942Vp7ePXak8XJ4A739vZSB3awPBhcM8bSTm9VJZoxnstMGbJyVOMY77ne5absiMwh2e95RtU5yGwn8wzLOjw8HFzT6/p+/hy/vLxss9nsyrXeFAAIQgGAIBQACEIBgCAUAAhCAYAgFAAIQgGAsNXktcufri89ZKxWq1v9+/xfVcWlzHXJlLuyMse9f7xftr9MKannFLvs/nqX5X777beS7Tx79mxwTbbgNsZi5fPV88E1m8Oa69t7CqM3BQCCUAAgCAUAglAAIAgFAIJQACAIBQCCUAAgbFVeq7BYLHILl8NLek+luu9OD09T69LXeMDP7eeS7bSWm9BWdT9N+Z774YcfSrZTWYbcLGrOZ+a6ZMu1p3vD34XeRd3j4+Mrf/bPP/+kt+NNAYAgFAAIQgGAIBQACEIBgCAUAAhCAYAgFAAIQgGAsFWjef563trDq39eOVouY4z7q9J7BF9mfGKmFdxarsmZaT1nxzVmvDh/Mbim6n4aY6O59/cgM0o1e56qznnltXv16tXgmsPDw9S2xsabAgBBKAAQhAIAQSgAEIQCAEEoABCEAgBBKAAQtiqvXf502Waz2Zc6li/i7OhscE2maNPbGAtQmYJba7mSW6bgVlmou+9630+V+6vaVmXZNfNcydyb5+fng2t+3fs1dUxVvCkAEIQCAEEoABCEAgBBKAAQhAIAQSgAEIQCAGGr8lpPVYWVTIHk9PC0ZF9ZvadgZQoylTKls6rCYPY+efFqePIadffmGMuXGdnjznynDpYHJfvLFD2Hjunvv/9ObaM1bwoAfEYoABCEAgBBKAAQhAIAQSgAEIQCAEEoABC6l9d6l1oWi8XgmmxhZ7OomdzU+xzs7e0NruldqJvyJLC7rHI6Wa/ttNb3uFvLTV6bKm8KAAShAEAQCgAEoQBAEAoABKEAQBAKAAShAEAQCgCEnc1mc20VcL1et/l8/ukfXrbWHl69trI1OsZm8Bg5T3fbXb6+6b9J4A5/vspm9HWjh9+/f9++//771lprl5eXbTabXbnWmwIAQSgAEIQCAEEoABCEAgBBKAAQhAIAQSgAELqP4zw/P0+ty5Q6MtvKjKKcsjEWe6oKV72LW2MsivUeM5nR+xyM8br0lH2G7R/vX/3DD/n9eVMAIAgFAIJQACAIBQCCUAAgCAUAglAAIAgFAMJWk9f++OOPtru7e6sd9i6T3ffiS5bzRG9TnrzWszBY8fk/f46bvAZAmlAAIAgFAIJQACAIBQCCUAAgCAUAglAAIJROXrt28s8XkCl1TLX4MsaJYtnCTmZqXuZeqTymMU56q1J53FOdmjdGVZ+vpChn8hoANyEUAAhCAYAgFAAIQgGAIBQACEIBgCAUAAhCAYCw1TjO9rK19vB2O7zrLcbeTc7z8/OS7VSOSa06pqrWcyVN3Zwxnqep/k0CFYzjBOBGhAIAQSgAEIQCAEEoABCEAgBBKAAQhAIAYavy2lDpgf4yBZnTw9PBNQfLg8E1mTGbY9V7/GdGz3GNCnXjHFtata+h/SmvAXAjQgGAIBQACEIBgCAUAAhCAYAgFAAIQgGAMNry2mq1Glzz7NmzwTW9p3eNcfLaxcXF4Jqqc5k11aIYtFZ3b3b7Hnxorf3y6Y/KawCkCQUAglAAIAgFAIJQACAIBQCCUAAgCAUAwmjLaxmZ4lbG3t5eyXYqVX221vqX1+5yUWyq07sqTfW4exvTeTJ5DYAbEQoABKEAQBAKAAShAEAQCgAEoQBAEAoABKEAQJh0ozkj0wxON5p3EmPxrj+dadlGc2ZsaebzZRrNY2x+Z0cVatiOT+9rN6aGcW8azQDciFAAIAgFAIJQACAIBQCCUAAgCAUAglAAINz58lpv2ULOkLOjs5LttJYrnVUdd2vjLABVfb4xfrZKlffBkMpzeZ+LaRnKawDciFAAIAgFAIJQACAIBQCCUAAgCAUAglAAICivtXFO76o8puwUtyFjnLxGf2MsiiknXk95DYAbEQoABKEAQBAKAAShAEAQCgAEoQBAEAoAhG+2WTx/PW/t4dU/n+okpakWbSrtH+8PrsmepzGWm6qM8dr1PpdV+1sulyXbyZrqPdebNwUAglAAIAgFAIJQACAIBQCCUAAgCAUAglAAIAgFAIJxnK22pTrGdvTZ0dngGqM2x2mM7fCqY1qtVqn9LRaL1Lohvc9l1f5Knk8fWmu/fPqjcZwApAkFAIJQACAIBQCCUAAgCAUAwuCQnc//j9X1ev1FD+ar+VC3qe7nKHHs7969G1xzZ6/t1CWu7xjvucwxvX//PrW7ss/X+1xW7a/i+fTZNgZaCMM9hb/++qs9ffq04KgA+NrevHnTnjx5cuXP/foIgDD4pvDx48f29u3b1lpru7u7bWdnfDNqAbjaZrOJXyM/fvy4PXhw9fvAYCgAcH/49REAQSgAEIQCAEEoABCEAgBBKAAQhAIA4T8Pk+oTM5FPcwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Пример генерации среды\n",
    "grid, start, finish = generate_environment(\n",
    "    n=40,\n",
    "    m=40,\n",
    "    p_walk=0.6,\n",
    "    p_obstacle=0.2,\n",
    "    number_mud=30, # должно быть пропорционально размерам сетки\n",
    ")\n",
    "\n",
    "# Визуализация среды\n",
    "visualize_array(np.array(grid), [start, finish])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bd0b2b",
   "metadata": {},
   "source": [
    "### Реализация Q-learning\n",
    "\n",
    "<img src=\"img/q-learning.png\" alt=\"Q-learning\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "166a940c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearning:\n",
    "    def __init__(self, alpha, epsilon, gamma):\n",
    "        self.alpha = alpha\n",
    "        self.epsilon = epsilon\n",
    "        self.gamma = gamma\n",
    "        # Параметр Q-функции: (state, action)\n",
    "        self.Q = dict()\n",
    "\n",
    "    # Возвращает текущее значение Q-функции для состояния state и действия action\n",
    "    # Для терминального состояния - 0\n",
    "    # Для неинициализированного состояния - 0\n",
    "    def _get_q_value(self, state, action):\n",
    "        if Environment.is_terminal(state):\n",
    "            return 0\n",
    "        return self.Q.get((state, action), 0)\n",
    "\n",
    "    # Возвращает максимум Q-функции по всем действиям из состояния state\n",
    "    def _best_action_value(self, state):\n",
    "        if Environment.is_terminal(state):\n",
    "            return 0\n",
    "        return max(self._get_q_value(state, a) for a in range(4))\n",
    "\n",
    "    # Выбор действия в состоянии state\n",
    "    def _choose_action(self, state):\n",
    "        # С вероятностью epsilon - равновероятно случайное действие\n",
    "        if random.random() < self.epsilon:\n",
    "            return randint(0, 3)\n",
    "        # Иначе - аргмаксимум Q-функции по всем действиям из состояния state\n",
    "        qs = [self._get_q_value(state, a) for a in range(4)]\n",
    "        return int(np.argmax(qs))\n",
    "\n",
    "    def learn(self, max_episodes, max_steps):\n",
    "        for _ in range(max_episodes):\n",
    "            n, m = randint(10, 20), randint(10, 20)\n",
    "            env = Environment(\n",
    "                    n=n,\n",
    "                    m=m,\n",
    "                    p_walk=0.5,\n",
    "                    p_obstacle=random.uniform(0.1, 0.2),\n",
    "                    number_mud=random.randint(int(5 * (n*m)/(20*20)), int(8 * (n*m)/(20*20))),\n",
    "                )\n",
    "            state = env.get_state()\n",
    "\n",
    "            self.epsilon = max(0.01, self.epsilon * 0.995)\n",
    "\n",
    "            for _ in range(max_steps):\n",
    "                if env.is_terminal(state):\n",
    "                    break\n",
    "\n",
    "                action = self._choose_action(state)\n",
    "                next_state, reward = env.step(action)\n",
    "\n",
    "                old_q = self._get_q_value(state, action)\n",
    "                target = reward + self.gamma * self._best_action_value(next_state)\n",
    "\n",
    "                self.Q[(state, action)] = old_q + self.alpha * (target - old_q)\n",
    "                state = next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b39ea52",
   "metadata": {},
   "source": [
    "#### Пример обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59e94af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = QLearning(alpha=0.1, epsilon=0.3, gamma=1)\n",
    "q.learn(max_episodes=20000, max_steps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b9a641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "MAX_STEPS = 5 * 10**4\n",
    "\n",
    "# Тестовый запуск обученной модели на новой случайной среде\n",
    "# Возвращает количество шагов агента до достижения финиша (но не более MAX_STEPS)\n",
    "def try_model():\n",
    "    n, m = 10, 10\n",
    "    env = Environment(\n",
    "        n=n,\n",
    "        m=m,\n",
    "        p_walk=0.5,\n",
    "        p_obstacle=random.uniform(0.1, 0.2),\n",
    "        number_mud=random.randint(int(5 * (n*m)/(20*20)), int(8 * (n*m)/(20*20)))\n",
    "    )\n",
    "\n",
    "    state = env.get_state()\n",
    "    path = [env.agent_position]\n",
    "\n",
    "    # Оптимальное действие в state - аргмаксимум Q-функции по всем действиям из state\n",
    "    def get_optimal_action(state):\n",
    "        qs = [q._get_q_value(state, a) for a in range(4)]\n",
    "        return int(np.argmax(qs))\n",
    "\n",
    "    for _ in range(MAX_STEPS):\n",
    "        if env.is_terminal(state):\n",
    "            break\n",
    "        action = get_optimal_action(state)\n",
    "        state, _ = env.step(action)\n",
    "        path.append(env.agent_position)\n",
    "\n",
    "    return len(path)\n",
    "\n",
    "# это тоже нагенерено чатгпт\n",
    "\n",
    "# --- Визуализация пути агента ---\n",
    "# grid = np.array(env.grid)\n",
    "# img = np.zeros((n, m, 3), dtype=float)\n",
    "\n",
    "# for i in range(n):\n",
    "#     for j in range(m):\n",
    "#         if grid[i,j] == 10:\n",
    "#             img[i,j] = [0,0,0]           # препятствие — чёрное\n",
    "#         elif grid[i,j] == 0:\n",
    "#             img[i,j] = [1,1,1]           # пустое — белое\n",
    "#         else:\n",
    "#             shade = 0.3 + 0.7*(grid[i,j]/10)  # болотный градиент\n",
    "#             img[i,j] = [0, shade, shade]\n",
    "\n",
    "# plt.imshow(img, origin='upper')\n",
    "# plt.scatter(env.start[1], env.start[0], c='green', marker='o', s=80, label='Start')\n",
    "# plt.scatter(env.finish[1], env.finish[0], c='red', marker='x', s=80, label='Finish')\n",
    "\n",
    "# # Рисуем путь агента\n",
    "# path_i, path_j = zip(*path)\n",
    "# plt.plot(path_j, path_i, color='blue', linewidth=2, label='Agent path')\n",
    "\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230d7a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 43., 119.,  65.,  93.,  30.,  63.,  38.,   6.,   3.,   3.]),\n",
       " array([ 1. ,  2.6,  4.2,  5.8,  7.4,  9. , 10.6, 12.2, 13.8, 15.4, 17. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Количество эпизодов\n",
    "N = 1000\n",
    "path_steps = []\n",
    "cnt_large = 0\n",
    "for _ in range(N):\n",
    "    steps = try_model()\n",
    "    if steps < MAX_STEPS:\n",
    "        path_steps.append(steps)\n",
    "    else:\n",
    "        cnt_large += 1\n",
    "\n",
    "    if _ % 100 == 0:\n",
    "        print(_)\n",
    "\n",
    "path_steps = sorted(path_steps)\n",
    "plt.hist(path_steps, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60bfb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "520\n"
     ]
    }
   ],
   "source": [
    "# Доля эпизодов, для которых не нашёлся путь за MAX_STEPS шагов\n",
    "print(cnt_large / N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd01e76",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64035e89",
   "metadata": {},
   "source": [
    "## SARSA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1108f64",
   "metadata": {},
   "source": [
    "### Реализация SARSA\n",
    "\n",
    "<img src=\"img/sarsa.png\" alt=\"SARSA\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "beb83ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sarsa:\n",
    "    def __init__(self, alpha, epsilon, gamma):\n",
    "        self.alpha = alpha\n",
    "        self.epsilon = epsilon\n",
    "        self.gamma = gamma\n",
    "        self.Q = dict()\n",
    "\n",
    "    # Возвращает текущее значение Q-функции для состояния state и действия action\n",
    "    # Для терминального состояния - 0\n",
    "    # Для неинициализированного состояния - 0\n",
    "    def _get_q_value(self, state, action):\n",
    "        if Environment.is_terminal(state):\n",
    "            return 0\n",
    "        return self.Q.get((state, action), 0)\n",
    "\n",
    "    # Возвращает максимум Q-функции по всем действиям из состояния state\n",
    "    def _best_action_value(self, state):\n",
    "        if Environment.is_terminal(state):\n",
    "            return 0\n",
    "        return max(self._get_q_value(state, a) for a in range(4))\n",
    "\n",
    "    # Выбор действия в состоянии state\n",
    "    def _choose_action(self, state):\n",
    "        # С вероятностью epsilon - равновероятно случайное действие\n",
    "        if random.random() < self.epsilon:\n",
    "            return randint(0, 3)\n",
    "        # Иначе - аргмаксимум Q-функции по всем действиям из состояния state\n",
    "        qs = [self._get_q_value(state, a) for a in range(4)]\n",
    "        return int(np.argmax(qs))\n",
    "\n",
    "    def learn(self, max_episodes, max_steps):\n",
    "        for _ in range(max_episodes):\n",
    "            n, m = randint(10, 20), randint(10, 20)\n",
    "            env = Environment(\n",
    "                    n=n,\n",
    "                    m=m,\n",
    "                    p_walk=0.5,\n",
    "                    p_obstacle=random.uniform(0.1, 0.2),\n",
    "                    number_mud=random.randint(int(5 * (n*m)/(20*20)), int(8 * (n*m)/(20*20))),\n",
    "                )\n",
    "            state = env.get_state()\n",
    "            action = self._choose_action(state)   # !!!\n",
    "\n",
    "            for _ in range(max_steps):\n",
    "                if env.is_terminal(state):\n",
    "                    break\n",
    "\n",
    "                next_state, reward = env.step(action)\n",
    "                next_action = self._choose_action(next_state)  # !!!\n",
    "\n",
    "                old_q = self._get_q_value(state, action)\n",
    "                target = reward + self.gamma *  self._get_q_value(next_state, next_action) # !!!\n",
    "\n",
    "                self.Q[(state, action)] = old_q + self.alpha * (target - old_q)\n",
    "                state = next_state\n",
    "                action = next_action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f265e519",
   "metadata": {},
   "source": [
    "#### Пример обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c82a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Sarsa(alpha=0.1, epsilon=0.3, gamma=1)\n",
    "s.learn(max_episodes=20000, max_steps=10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
